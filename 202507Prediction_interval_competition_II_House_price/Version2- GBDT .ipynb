{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":99650,"databundleVersionId":11917221,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PI-II: Demo QRF\n\nA simple example of fitting a quantile regression forest (QRF) using the [quantile-forest](https://zillow.github.io/quantile-forest/) package to estimate prediction intervals.\n\nStarter script for the [Prediction interval competition II: House price](https://www.kaggle.com/competitions/prediction-interval-competition-ii-house-price/overview) competition.","metadata":{}},{"cell_type":"code","source":"!pip install -q quantile-forest 2>/dev/null  # package for quantile regression forests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:05:37.231870Z","iopub.execute_input":"2025-07-08T07:05:37.232186Z","iopub.status.idle":"2025-07-08T07:05:40.925949Z","shell.execute_reply.started":"2025-07-08T07:05:37.232161Z","shell.execute_reply":"2025-07-08T07:05:40.924792Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom quantile_forest import RandomForestQuantileRegressor\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport lightgbm as lgb\nfrom typing import Tuple\n\nrandom_state = 0\nnp.random.seed(random_state)\n\n# Competition variables.\nbase_path = \"/kaggle/input/prediction-interval-competition-ii-house-price/\"\nalpha = 0.1  # the specified competition alpha (i.e., 90% coverage)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:05:40.928524Z","iopub.execute_input":"2025-07-08T07:05:40.928819Z","iopub.status.idle":"2025-07-08T07:05:40.936332Z","shell.execute_reply.started":"2025-07-08T07:05:40.928792Z","shell.execute_reply":"2025-07-08T07:05:40.934986Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def winkler_score(y_true, lower, upper, alpha=0.1, return_coverage=False):\n    \"\"\"Compute the Winkler Interval Score for prediction intervals.\n\n    Args:\n        y_true (array-like): True observed values.\n        lower (array-like): Lower bounds of prediction intervals.\n        upper (array-like): Upper bounds of prediction intervals.\n        alpha (float): Significance level (e.g., 0.1 for 90% intervals).\n        return_coverage (bool): If True, also return empirical coverage.\n\n    Returns:\n        score (float): Mean Winkler Score.\n        coverage (float, optional): Proportion of true values within intervals.\n    \"\"\"\n    y_true = np.asarray(y_true)\n    lower = np.asarray(lower)\n    upper = np.asarray(upper)\n\n    width = upper - lower\n    penalty_lower = 2 / alpha * (lower - y_true)\n    penalty_upper = 2 / alpha * (y_true - upper)\n\n    score = width.copy()\n    score += np.where(y_true < lower, penalty_lower, 0)\n    score += np.where(y_true > upper, penalty_upper, 0)\n\n    if return_coverage:\n        inside = (y_true >= lower) & (y_true <= upper)\n        coverage = np.mean(inside)\n        return np.mean(score), coverage\n\n    return np.mean(score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:05:40.937374Z","iopub.execute_input":"2025-07-08T07:05:40.937768Z","iopub.status.idle":"2025-07-08T07:05:40.964464Z","shell.execute_reply.started":"2025-07-08T07:05:40.937740Z","shell.execute_reply":"2025-07-08T07:05:40.963702Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"df = pd.read_csv(base_path + \"dataset.csv\", index_col=\"id\", parse_dates=[\"sale_date\"])\ndf_test = pd.read_csv(base_path + \"test.csv\", index_col=\"id\", parse_dates=[\"sale_date\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:05:40.966715Z","iopub.execute_input":"2025-07-08T07:05:40.966996Z","iopub.status.idle":"2025-07-08T07:05:42.598475Z","shell.execute_reply.started":"2025-07-08T07:05:40.966976Z","shell.execute_reply":"2025-07-08T07:05:42.597615Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"## Data Preparation\n\nPrepare the data, including separating features and target, encoding categoricals, imputation, and simple feature engineering.","metadata":{}},{"cell_type":"code","source":"# Split features and target.\nX = df.drop(\"sale_price\", axis=1)\ny = df[\"sale_price\"]\n\n# Split train/val and test.\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.50, random_state=random_state\n)\nX_test = df_test.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:05:42.599310Z","iopub.execute_input":"2025-07-08T07:05:42.599545Z","iopub.status.idle":"2025-07-08T07:05:42.753706Z","shell.execute_reply.started":"2025-07-08T07:05:42.599525Z","shell.execute_reply":"2025-07-08T07:05:42.752923Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Ordinal encoding.\ncat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\nencoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\nX_train[cat_cols] = encoder.fit_transform(X_train[cat_cols])\nX_val[cat_cols] = encoder.transform(X_val[cat_cols])\nX_test[cat_cols] = encoder.transform(X_test[cat_cols])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:05:42.754481Z","iopub.execute_input":"2025-07-08T07:05:42.754773Z","iopub.status.idle":"2025-07-08T07:05:43.689361Z","shell.execute_reply.started":"2025-07-08T07:05:42.754751Z","shell.execute_reply":"2025-07-08T07:05:43.688391Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Imputation.\nnum_cols = X_train.select_dtypes(include=\"number\").columns.tolist()\n\nnum_imputer = SimpleImputer(strategy=\"median\")\ncat_imputer = SimpleImputer(strategy=\"most_frequent\")\n\n\ndef impute(df, cols, imputer, fit=False):\n    \"\"\"Helper function for imputation.\"\"\"\n    if fit:\n        return pd.DataFrame(imputer.fit_transform(df[cols]), columns=cols, index=df.index)\n    else:\n        return pd.DataFrame(imputer.transform(df[cols]), columns=cols, index=df.index)\n\n\nX_train[num_cols] = impute(X_train, num_cols, num_imputer, fit=True)\nX_val[num_cols] = impute(X_val, num_cols, num_imputer)\nX_test[num_cols] = impute(X_test, num_cols, num_imputer)\n\nX_train[cat_cols] = impute(X_train, cat_cols, cat_imputer, fit=True)\nX_val[cat_cols] = impute(X_val, cat_cols, cat_imputer)\nX_test[cat_cols] = impute(X_test, cat_cols, cat_imputer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:05:43.690359Z","iopub.execute_input":"2025-07-08T07:05:43.690685Z","iopub.status.idle":"2025-07-08T07:05:44.738853Z","shell.execute_reply.started":"2025-07-08T07:05:43.690656Z","shell.execute_reply":"2025-07-08T07:05:44.738015Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"class SaleDateEncoder(BaseEstimator, TransformerMixin):\n    \"\"\"Encode sale date as a week of the year feature.\"\"\"\n\n    def __init__(self, date_column=\"sale_date\"):\n        self.date_column = date_column\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X = X.assign(\n            **{\n                \"sale_week\": lambda x: x[\"sale_date\"].dt.isocalendar().week,\n            }\n        ).drop(columns=[\"sale_date\"])\n        return X\n\n    def fit_transform(self, X):\n        return self.fit(self, X).transform(X)\n\n\n# Sale date encoding.\nsaledate_encoder = SaleDateEncoder(date_column=\"sale_date\")\nX_train = saledate_encoder.fit_transform(X_train)\nX_val = saledate_encoder.transform(X_val)\nX_test = saledate_encoder.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:05:44.739601Z","iopub.execute_input":"2025-07-08T07:05:44.739873Z","iopub.status.idle":"2025-07-08T07:05:44.927625Z","shell.execute_reply.started":"2025-07-08T07:05:44.739853Z","shell.execute_reply":"2025-07-08T07:05:44.926706Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"## Model Fitting\n\nFit a QRF model and use it to estimate a nominal marginal coverage of 90% (quantiles 0.05 and 0.95).","metadata":{}},{"cell_type":"code","source":"class GBDTIntervalRegressor(BaseEstimator, RegressorMixin):\n    \"\"\"\n    基于 scikit-learn GBDT / LightGBM 的分位数回归器，\n    支持同时训练多个分位数模型并输出区间。\n    \"\"\"\n\n    def __init__(\n        self,\n        backend: str = \"sklearn\",     # 或 \"lightgbm\"\n        n_estimators: int = 100,\n        learning_rate: float = 0.1,\n        max_depth: int = 3,\n        quantiles: Tuple[float, float, float] = (0.05, 0.5, 0.95),\n        **kwargs\n    ):\n        self.backend = backend\n        self.n_estimators = n_estimators\n        self.learning_rate = learning_rate\n        self.max_depth = max_depth\n        self.quantiles = quantiles\n        self.kwargs = kwargs\n        self.models_ = {}  # 存放 q 下界、中位数、上界三棵树\n\n    def fit(self, X, y):\n        \"\"\"\n        训练三个子模型：下分位数、中位数、上分位数\n        \"\"\"\n        for q in self.quantiles:\n            if self.backend == \"sklearn\":\n                model = GradientBoostingRegressor(\n                    loss=\"quantile\", alpha=q,\n                    n_estimators=self.n_estimators,\n                    learning_rate=self.learning_rate,\n                    max_depth=self.max_depth,\n                    **self.kwargs\n                )\n            else:  # lightgbm\n                params = dict(\n                    objective=\"quantile\",\n                    alpha=q,\n                    n_estimators=self.n_estimators,\n                    learning_rate=self.learning_rate,\n                    max_depth=self.max_depth,\n                    **self.kwargs\n                )\n                model = lgb.LGBMRegressor(**params)\n            model.fit(X, y)\n            self.models_[q] = model\n        return self\n\n    def predict(self, X) -> np.ndarray:\n        lower = self.models_[self.quantiles[0]].predict(X)\n        upper = self.models_[self.quantiles[2]].predict(X)\n        # 返回一个 (n_samples, 2) 的矩阵\n        return np.stack((lower, upper), axis=1)\n\n\n    @property\n    def feature_importances_(self):\n        \"\"\"返回各个模型的重要性（可以取平均或单独分析）。\"\"\"\n        imps = {q: m.feature_importances_ for q, m in self.models_.items()}\n        return imps\n\n    def get_params(self, deep=True):\n        \"\"\"支持 sklearn 参数搜索\"\"\"\n        return {\n            \"backend\": self.backend,\n            \"n_estimators\": self.n_estimators,\n            \"learning_rate\": self.learning_rate,\n            \"max_depth\": self.max_depth,\n            \"quantiles\": self.quantiles,\n            **self.kwargs,\n        }\n\n    def set_params(self, **params):\n        for k, v in params.items():\n            setattr(self, k, v)\n        return self","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:05:44.928802Z","iopub.execute_input":"2025-07-08T07:05:44.929674Z","iopub.status.idle":"2025-07-08T07:05:44.940808Z","shell.execute_reply.started":"2025-07-08T07:05:44.929616Z","shell.execute_reply":"2025-07-08T07:05:44.939936Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"model = GBDTIntervalRegressor().fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:05:44.943069Z","iopub.execute_input":"2025-07-08T07:05:44.943342Z","iopub.status.idle":"2025-07-08T07:07:54.162286Z","shell.execute_reply.started":"2025-07-08T07:05:44.943305Z","shell.execute_reply":"2025-07-08T07:07:54.161305Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"y_val_pred = model.predict(X_val)\ny_val_pred = pd.DataFrame(y_val_pred, columns=[\"pi_lower\", \"pi_upper\"])\n#产生每个样本的预测区间并保存","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:07:54.163393Z","iopub.execute_input":"2025-07-08T07:07:54.163742Z","iopub.status.idle":"2025-07-08T07:07:54.633476Z","shell.execute_reply.started":"2025-07-08T07:07:54.163712Z","shell.execute_reply":"2025-07-08T07:07:54.632538Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"## Evaluation\n\nEvaluate the QRF predictions on the validation data.","metadata":{}},{"cell_type":"code","source":"mws, coverage = winkler_score(\n    y_val,\n    y_val_pred[\"pi_lower\"],\n    y_val_pred[\"pi_upper\"],\n    alpha=alpha,\n    return_coverage=True,\n)\n\nprint(\"Mean Winkler Score:\", round(mws, 2))\nprint(\"Coverage:\", round(coverage * 100, 1), \"%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:07:54.634364Z","iopub.execute_input":"2025-07-08T07:07:54.634649Z","iopub.status.idle":"2025-07-08T07:07:54.644400Z","shell.execute_reply.started":"2025-07-08T07:07:54.634610Z","shell.execute_reply":"2025-07-08T07:07:54.643554Z"}},"outputs":[{"name":"stdout","text":"Mean Winkler Score: 901740.02\nCoverage: 89.8 %\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"# Predict intervals on test set.\ntest_preds = model.predict(X_test)\n\nsample_submission = pd.read_csv(base_path + \"sample_submission.csv\")\nsample_submission[\"pi_lower\"] = test_preds[:, 0]\nsample_submission[\"pi_upper\"] = test_preds[:, 1]\nsample_submission.to_csv(\"submission.csv\", index=False)\n\nsample_submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T07:10:34.508238Z","iopub.execute_input":"2025-07-08T07:10:34.508578Z","iopub.status.idle":"2025-07-08T07:10:36.504208Z","shell.execute_reply.started":"2025-07-08T07:10:34.508553Z","shell.execute_reply":"2025-07-08T07:10:36.503436Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"            id       pi_lower      pi_upper\n0       200000  553799.744720  1.056133e+06\n1       200001  628734.264791  1.844173e+06\n2       200002  331887.387839  1.299444e+06\n3       200003  216573.992742  4.376405e+05\n4       200004  271605.456153  1.309509e+06\n...        ...            ...           ...\n199995  399995  219653.639384  8.934583e+05\n199996  399996  239270.515570  8.018955e+05\n199997  399997  194613.374663  5.396006e+05\n199998  399998  390722.163434  1.424492e+06\n199999  399999  461542.412974  1.007827e+06\n\n[200000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>pi_lower</th>\n      <th>pi_upper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200000</td>\n      <td>553799.744720</td>\n      <td>1.056133e+06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>200001</td>\n      <td>628734.264791</td>\n      <td>1.844173e+06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>200002</td>\n      <td>331887.387839</td>\n      <td>1.299444e+06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>200003</td>\n      <td>216573.992742</td>\n      <td>4.376405e+05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200004</td>\n      <td>271605.456153</td>\n      <td>1.309509e+06</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>399995</td>\n      <td>219653.639384</td>\n      <td>8.934583e+05</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>399996</td>\n      <td>239270.515570</td>\n      <td>8.018955e+05</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>399997</td>\n      <td>194613.374663</td>\n      <td>5.396006e+05</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>399998</td>\n      <td>390722.163434</td>\n      <td>1.424492e+06</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>399999</td>\n      <td>461542.412974</td>\n      <td>1.007827e+06</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":46}]}
