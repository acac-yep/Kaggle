{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a306d55",
   "metadata": {
    "papermill": {
     "duration": 0.004667,
     "end_time": "2025-07-14T11:24:12.413055",
     "exception": false,
     "start_time": "2025-07-14T11:24:12.408388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PI-II: Demo QRF\n",
    "\n",
    "A simple example of fitting a quantile regression forest (QRF) using the [quantile-forest](https://zillow.github.io/quantile-forest/) package to estimate prediction intervals.\n",
    "\n",
    "Starter script for the [Prediction interval competition II: House price](https://www.kaggle.com/competitions/prediction-interval-competition-ii-house-price/overview) competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58eab97f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:12.422799Z",
     "iopub.status.busy": "2025-07-14T11:24:12.422378Z",
     "iopub.status.idle": "2025-07-14T11:24:22.353399Z",
     "shell.execute_reply": "2025-07-14T11:24:22.352350Z"
    },
    "papermill": {
     "duration": 9.937958,
     "end_time": "2025-07-14T11:24:22.355321",
     "exception": false,
     "start_time": "2025-07-14T11:24:12.417363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q quantile-forest 2>/dev/null  # package for quantile regression forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66af864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:22.365129Z",
     "iopub.status.busy": "2025-07-14T11:24:22.364808Z",
     "iopub.status.idle": "2025-07-14T11:24:30.509441Z",
     "shell.execute_reply": "2025-07-14T11:24:30.508468Z"
    },
    "papermill": {
     "duration": 8.151668,
     "end_time": "2025-07-14T11:24:30.511276",
     "exception": false,
     "start_time": "2025-07-14T11:24:22.359608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76204f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:30.521605Z",
     "iopub.status.busy": "2025-07-14T11:24:30.521109Z",
     "iopub.status.idle": "2025-07-14T11:24:35.520749Z",
     "shell.execute_reply": "2025-07-14T11:24:35.519785Z"
    },
    "papermill": {
     "duration": 5.006629,
     "end_time": "2025-07-14T11:24:35.522419",
     "exception": false,
     "start_time": "2025-07-14T11:24:30.515790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'device': 'cpu',\n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0,\n",
    "    'learning_rate': 0.01,\n",
    "    # …\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d00603e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:35.533247Z",
     "iopub.status.busy": "2025-07-14T11:24:35.532032Z",
     "iopub.status.idle": "2025-07-14T11:24:35.536979Z",
     "shell.execute_reply": "2025-07-14T11:24:35.536197Z"
    },
    "papermill": {
     "duration": 0.011595,
     "end_time": "2025-07-14T11:24:35.538303",
     "exception": false,
     "start_time": "2025-07-14T11:24:35.526708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# Competition variables.\n",
    "base_path = \"/kaggle/input/prediction-interval-competition-ii-house-price/\"\n",
    "alpha = 0.1  # the specified competition alpha (i.e., 90% coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd4a2ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:35.547810Z",
     "iopub.status.busy": "2025-07-14T11:24:35.547455Z",
     "iopub.status.idle": "2025-07-14T11:24:40.146057Z",
     "shell.execute_reply": "2025-07-14T11:24:40.145067Z"
    },
    "papermill": {
     "duration": 4.60543,
     "end_time": "2025-07-14T11:24:40.147872",
     "exception": false,
     "start_time": "2025-07-14T11:24:35.542442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. 读入 CSV\n",
    "df = pd.read_csv(base_path + \"dataset.csv\")\n",
    "\n",
    "# 2. 删除指定列（不修改原 df 返回新对象）\n",
    "df_new = df.drop(columns='sale_nbr')\n",
    "\n",
    "# 3. 保存为新的 CSV（覆盖旧文件也可以）\n",
    "df_new.to_csv('dataset_no_sale_nbr.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8ac483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:40.159092Z",
     "iopub.status.busy": "2025-07-14T11:24:40.158736Z",
     "iopub.status.idle": "2025-07-14T11:24:40.165683Z",
     "shell.execute_reply": "2025-07-14T11:24:40.164916Z"
    },
    "papermill": {
     "duration": 0.014563,
     "end_time": "2025-07-14T11:24:40.166979",
     "exception": false,
     "start_time": "2025-07-14T11:24:40.152416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "def winkler_score(y_true, lower, upper, alpha=0.1, return_coverage=False):\n",
    "    \"\"\"Compute the Winkler Interval Score for prediction intervals.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): True observed values.\n",
    "        lower (array-like): Lower bounds of prediction intervals.\n",
    "        upper (array-like): Upper bounds of prediction intervals.\n",
    "        alpha (float): Significance level (e.g., 0.1 for 90% intervals).\n",
    "        return_coverage (bool): If True, also return empirical coverage.\n",
    "\n",
    "    Returns:\n",
    "        score (float): Mean Winkler Score.\n",
    "        coverage (float, optional): Proportion of true values within intervals.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    lower = np.asarray(lower)\n",
    "    upper = np.asarray(upper)\n",
    "\n",
    "    width = upper - lower\n",
    "    penalty_lower = 2 / alpha * (lower - y_true)\n",
    "    penalty_upper = 2 / alpha * (y_true - upper)\n",
    "\n",
    "    score = width.copy()\n",
    "    score += np.where(y_true < lower, penalty_lower, 0)\n",
    "    score += np.where(y_true > upper, penalty_upper, 0)\n",
    "\n",
    "    if return_coverage:\n",
    "        inside = (y_true >= lower) & (y_true <= upper)\n",
    "        coverage = np.mean(inside)\n",
    "        return np.mean(score), coverage\n",
    "\n",
    "    return np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4d9cc42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:40.175925Z",
     "iopub.status.busy": "2025-07-14T11:24:40.175581Z",
     "iopub.status.idle": "2025-07-14T11:24:42.316151Z",
     "shell.execute_reply": "2025-07-14T11:24:42.315215Z"
    },
    "papermill": {
     "duration": 2.146942,
     "end_time": "2025-07-14T11:24:42.317956",
     "exception": false,
     "start_time": "2025-07-14T11:24:40.171014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(base_path + \"dataset.csv\", index_col=\"id\", parse_dates=[\"sale_date\"])\n",
    "df_test = pd.read_csv(base_path + \"test.csv\", index_col=\"id\", parse_dates=[\"sale_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168ca5b",
   "metadata": {
    "papermill": {
     "duration": 0.003721,
     "end_time": "2025-07-14T11:24:42.325953",
     "exception": false,
     "start_time": "2025-07-14T11:24:42.322232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "Prepare the data, including separating features and target, encoding categoricals, imputation, and simple feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11c4192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:42.335093Z",
     "iopub.status.busy": "2025-07-14T11:24:42.334744Z",
     "iopub.status.idle": "2025-07-14T11:24:42.474088Z",
     "shell.execute_reply": "2025-07-14T11:24:42.473135Z"
    },
    "papermill": {
     "duration": 0.145955,
     "end_time": "2025-07-14T11:24:42.475749",
     "exception": false,
     "start_time": "2025-07-14T11:24:42.329794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split features and target.\n",
    "X = df.drop(\"sale_price\", axis=1)\n",
    "y = df[\"sale_price\"]\n",
    "\n",
    "# Split train/val and test.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=random_state\n",
    ")\n",
    "X_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c35760e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:42.485093Z",
     "iopub.status.busy": "2025-07-14T11:24:42.484811Z",
     "iopub.status.idle": "2025-07-14T11:24:43.420271Z",
     "shell.execute_reply": "2025-07-14T11:24:43.419370Z"
    },
    "papermill": {
     "duration": 0.942071,
     "end_time": "2025-07-14T11:24:43.421992",
     "exception": false,
     "start_time": "2025-07-14T11:24:42.479921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#对类别特征的编码\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "X_train[cat_cols] = encoder.fit_transform(X_train[cat_cols])\n",
    "X_val[cat_cols] = encoder.transform(X_val[cat_cols])\n",
    "X_test[cat_cols] = encoder.transform(X_test[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a972737c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:43.431522Z",
     "iopub.status.busy": "2025-07-14T11:24:43.431208Z",
     "iopub.status.idle": "2025-07-14T11:24:44.891790Z",
     "shell.execute_reply": "2025-07-14T11:24:44.891069Z"
    },
    "papermill": {
     "duration": 1.46725,
     "end_time": "2025-07-14T11:24:44.893372",
     "exception": false,
     "start_time": "2025-07-14T11:24:43.426122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对缺失值的插补填充\n",
    "num_cols = X_train.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "\n",
    "def impute(df, cols, imputer, fit=False):\n",
    "    \"\"\"Helper function for imputation.\"\"\"\n",
    "    if fit:\n",
    "        return pd.DataFrame(imputer.fit_transform(df[cols]), columns=cols, index=df.index)\n",
    "    else:\n",
    "        return pd.DataFrame(imputer.transform(df[cols]), columns=cols, index=df.index)\n",
    "\n",
    "\n",
    "X_train[num_cols] = impute(X_train, num_cols, num_imputer, fit=True)\n",
    "X_val[num_cols] = impute(X_val, num_cols, num_imputer)\n",
    "X_test[num_cols] = impute(X_test, num_cols, num_imputer)\n",
    "\n",
    "X_train[cat_cols] = impute(X_train, cat_cols, cat_imputer, fit=True)\n",
    "X_val[cat_cols] = impute(X_val, cat_cols, cat_imputer)\n",
    "X_test[cat_cols] = impute(X_test, cat_cols, cat_imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d0d4e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:44.902800Z",
     "iopub.status.busy": "2025-07-14T11:24:44.902473Z",
     "iopub.status.idle": "2025-07-14T11:24:45.124455Z",
     "shell.execute_reply": "2025-07-14T11:24:45.123697Z"
    },
    "papermill": {
     "duration": 0.228504,
     "end_time": "2025-07-14T11:24:45.126114",
     "exception": false,
     "start_time": "2025-07-14T11:24:44.897610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#一个编码器将销售日期转换为每年中的周数，并应用于训练集、验证集和测试集\n",
    "class SaleDateEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Encode sale date as a week of the year feature.\"\"\"\n",
    "\n",
    "    def __init__(self, date_column=\"sale_date\"):\n",
    "        self.date_column = date_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.assign(\n",
    "            **{\n",
    "                \"sale_week\": lambda x: x[\"sale_date\"].dt.isocalendar().week,\n",
    "            }\n",
    "        ).drop(columns=[\"sale_date\"])\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(self, X).transform(X)\n",
    "\n",
    "\n",
    "# Sale date encoding.\n",
    "saledate_encoder = SaleDateEncoder(date_column=\"sale_date\")\n",
    "X_train = saledate_encoder.fit_transform(X_train)\n",
    "X_val = saledate_encoder.transform(X_val)\n",
    "X_test = saledate_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d9ceef",
   "metadata": {
    "papermill": {
     "duration": 0.003721,
     "end_time": "2025-07-14T11:24:45.134027",
     "exception": false,
     "start_time": "2025-07-14T11:24:45.130306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Fitting\n",
    "\n",
    "Fit a QRF model and use it to estimate a nominal marginal coverage of 90% (quantiles 0.05 and 0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b8afe43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:45.143222Z",
     "iopub.status.busy": "2025-07-14T11:24:45.142901Z",
     "iopub.status.idle": "2025-07-14T11:24:45.153476Z",
     "shell.execute_reply": "2025-07-14T11:24:45.152693Z"
    },
    "papermill": {
     "duration": 0.01691,
     "end_time": "2025-07-14T11:24:45.154902",
     "exception": false,
     "start_time": "2025-07-14T11:24:45.137992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GBDTIntervalRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    基于 LightGBM 的分位数回归器，支持多个分位点训练并输出预测区间。\n",
    "    默认使用 LightGBM，保留 sklearn GBDT 兼容接口。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        backend: str = \"lightgbm\",   # 默认改为 lightgbm\n",
    "        n_estimators: int = 2000,\n",
    "        learning_rate: float = 0.01,\n",
    "        max_depth: int = 10,          # LightGBM 用 -1 表示无深度限制\n",
    "        quantiles: Tuple[float, float, float] = (0.04, 0.5, 0.96),\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.backend = backend\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.quantiles = quantiles\n",
    "        self.kwargs = kwargs\n",
    "        self.models_ = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for q in self.quantiles:\n",
    "            if self.backend == \"sklearn\":\n",
    "                # sklearn GBDT\n",
    "                from sklearn.ensemble import GradientBoostingRegressor\n",
    "                model = GradientBoostingRegressor(\n",
    "                    loss=\"quantile\",\n",
    "                    alpha=q,\n",
    "                    n_estimators=self.n_estimators,\n",
    "                    learning_rate=self.learning_rate,\n",
    "                    max_depth=self.max_depth,\n",
    "                    **self.kwargs\n",
    "                )\n",
    "            else:\n",
    "                # LightGBM 量化回归\n",
    "                params = dict(\n",
    "                    objective=\"quantile\",\n",
    "                    alpha=q,\n",
    "                    n_estimators=self.n_estimators,\n",
    "                    learning_rate=self.learning_rate,\n",
    "                    max_depth=self.max_depth,\n",
    "                    verbose=-1,\n",
    "                    **self.kwargs\n",
    "                )\n",
    "                model = lgb.LGBMRegressor(**params)\n",
    "            model.fit(X, y)\n",
    "            self.models_[q] = model\n",
    "        return self\n",
    "\n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        lower = self.models_[self.quantiles[0]].predict(X)\n",
    "        upper = self.models_[self.quantiles[2]].predict(X)\n",
    "        # 返回一个 (n_samples, 2) 的数组，分别是下界和上界\n",
    "        return np.stack((lower, upper), axis=1)\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        # 返回所有分位数模型的重要性字典\n",
    "        return {q: m.feature_importances_ for q, m in self.models_.items()}\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            \"backend\": self.backend,\n",
    "            \"n_estimators\": self.n_estimators,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"max_depth\": self.max_depth,\n",
    "            \"quantiles\": self.quantiles,\n",
    "            **self.kwargs,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for k, v in params.items():\n",
    "            setattr(self, k, v)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f08ac9b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:24:45.165220Z",
     "iopub.status.busy": "2025-07-14T11:24:45.164324Z",
     "iopub.status.idle": "2025-07-14T11:26:10.944289Z",
     "shell.execute_reply": "2025-07-14T11:26:10.943251Z"
    },
    "papermill": {
     "duration": 85.786619,
     "end_time": "2025-07-14T11:26:10.946138",
     "exception": false,
     "start_time": "2025-07-14T11:24:45.159519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GBDTIntervalRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9acf04a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:26:10.956058Z",
     "iopub.status.busy": "2025-07-14T11:26:10.955770Z",
     "iopub.status.idle": "2025-07-14T11:26:20.007194Z",
     "shell.execute_reply": "2025-07-14T11:26:20.006149Z"
    },
    "papermill": {
     "duration": 9.058285,
     "end_time": "2025-07-14T11:26:20.008972",
     "exception": false,
     "start_time": "2025-07-14T11:26:10.950687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(X_val)\n",
    "y_val_pred = pd.DataFrame(y_val_pred, columns=[\"pi_lower\", \"pi_upper\"])\n",
    "#产生每个样本的预测区间并保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7919f6e3",
   "metadata": {
    "papermill": {
     "duration": 0.003971,
     "end_time": "2025-07-14T11:26:20.017270",
     "exception": false,
     "start_time": "2025-07-14T11:26:20.013299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluate the QRF predictions on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca8ec1e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:26:20.026410Z",
     "iopub.status.busy": "2025-07-14T11:26:20.025934Z",
     "iopub.status.idle": "2025-07-14T11:26:20.037396Z",
     "shell.execute_reply": "2025-07-14T11:26:20.036436Z"
    },
    "papermill": {
     "duration": 0.017634,
     "end_time": "2025-07-14T11:26:20.038721",
     "exception": false,
     "start_time": "2025-07-14T11:26:20.021087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Winkler Score: 827980.12\n",
      "Coverage: 90.7 %\n"
     ]
    }
   ],
   "source": [
    "mws, coverage = winkler_score(\n",
    "    y_val,\n",
    "    y_val_pred[\"pi_lower\"],\n",
    "    y_val_pred[\"pi_upper\"],\n",
    "    alpha=alpha,\n",
    "    return_coverage=True,\n",
    ")\n",
    "\n",
    "print(\"Mean Winkler Score:\", round(mws, 2))\n",
    "print(\"Coverage:\", round(coverage * 100, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6455d97",
   "metadata": {
    "papermill": {
     "duration": 0.003884,
     "end_time": "2025-07-14T11:26:20.046746",
     "exception": false,
     "start_time": "2025-07-14T11:26:20.042862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a7af85f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:26:20.056618Z",
     "iopub.status.busy": "2025-07-14T11:26:20.055819Z",
     "iopub.status.idle": "2025-07-14T11:27:05.973477Z",
     "shell.execute_reply": "2025-07-14T11:27:05.972191Z"
    },
    "papermill": {
     "duration": 45.930837,
     "end_time": "2025-07-14T11:27:05.981690",
     "exception": false,
     "start_time": "2025-07-14T11:26:20.050853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pi_lower</th>\n",
       "      <th>pi_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>642011.810095</td>\n",
       "      <td>1.093347e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>614351.686402</td>\n",
       "      <td>1.713346e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>349692.663876</td>\n",
       "      <td>9.706599e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>218036.392805</td>\n",
       "      <td>5.469614e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>398831.808317</td>\n",
       "      <td>1.265153e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>399995</td>\n",
       "      <td>212100.007245</td>\n",
       "      <td>9.834077e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>399996</td>\n",
       "      <td>231725.122328</td>\n",
       "      <td>6.994209e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>399997</td>\n",
       "      <td>196062.032326</td>\n",
       "      <td>5.189138e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>399998</td>\n",
       "      <td>405223.707654</td>\n",
       "      <td>1.238750e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>399999</td>\n",
       "      <td>480179.686505</td>\n",
       "      <td>7.688619e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       pi_lower      pi_upper\n",
       "0       200000  642011.810095  1.093347e+06\n",
       "1       200001  614351.686402  1.713346e+06\n",
       "2       200002  349692.663876  9.706599e+05\n",
       "3       200003  218036.392805  5.469614e+05\n",
       "4       200004  398831.808317  1.265153e+06\n",
       "...        ...            ...           ...\n",
       "199995  399995  212100.007245  9.834077e+05\n",
       "199996  399996  231725.122328  6.994209e+05\n",
       "199997  399997  196062.032326  5.189138e+05\n",
       "199998  399998  405223.707654  1.238750e+06\n",
       "199999  399999  480179.686505  7.688619e+05\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict intervals on test set.\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "sample_submission = pd.read_csv(base_path + \"sample_submission.csv\")\n",
    "sample_submission[\"pi_lower\"] = test_preds[:, 0]\n",
    "sample_submission[\"pi_upper\"] = test_preds[:, 1]\n",
    "sample_submission.to_csv(\"submission.csv\",\n",
    "                         index=False,\n",
    "                         float_format=\"%.6f\")\n",
    "\n",
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11917221,
     "sourceId": 99650,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 182.039002,
   "end_time": "2025-07-14T11:27:08.834488",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-14T11:24:06.795486",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
